{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import multiprocessing\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"input/\"\n",
    "columns = ['Text', 'Class']\n",
    "base = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in os.listdir(BASE_DIR):\n",
    "    path = os.path.join(BASE_DIR, file)\n",
    "    df = pd.read_csv(path, sep=\"\\t\", header=None, names=columns)\n",
    "    dfs.append(df)\n",
    "base = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
    "    return text.lower().split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(base, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['Text']), tags=[r.Class]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['Text']), tags=[r.Class]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1072110.73it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2198/2198 [00:00<00:00, 451694.28it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1177705.70it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1374341.11it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 921171.08it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1355149.23it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1392820.70it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1460564.04it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1277057.79it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1549946.23it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1480025.72it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1269670.87it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1394717.12it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1284531.17it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1093085.15it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1313072.24it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1451823.65it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1191249.54it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1361956.00it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1308970.64it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1430201.71it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1389461.97it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1173508.17it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1304340.72it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1068012.07it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1239790.24it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1113953.62it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 555165.61it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 943321.42it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1314757.59it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 787013.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.92 s, sys: 658 ms, total: 4.58 s\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('opening', 0.33626219630241394),\n",
       " ('big', 0.2923218905925751),\n",
       " ('earpiece', 0.29195964336395264),\n",
       " ('sashimi', 0.28428804874420166),\n",
       " ('nyc', 0.2626972794532776),\n",
       " ('ipod', 0.26215213537216187),\n",
       " ('focus', 0.26033657789230347),\n",
       " ('as', 0.2594040036201477),\n",
       " ('dessert', 0.25527170300483704),\n",
       " ('choice', 0.2537538707256317)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.wv.most_similar('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('possibly', 0.379730224609375),\n",
       " ('wait', 0.29852789640426636),\n",
       " ('charged', 0.2856979966163635),\n",
       " ('problem', 0.2828962802886963),\n",
       " ('40', 0.28117772936820984),\n",
       " ('including', 0.2790653705596924),\n",
       " ('james', 0.2694108486175537),\n",
       " ('children', 0.2665039598941803),\n",
       " ('seeing', 0.2647099494934082),\n",
       " ('sorry', 0.2608293294906616)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.wv.most_similar('hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2198/2198 [00:00<00:00, 746605.13it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2198/2198 [00:00<00:00, 570487.64it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 656723.19it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1234973.90it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 906141.16it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1192019.68it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 698415.17it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1530391.80it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1079012.19it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 950322.67it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1102892.71it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1378657.12it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1492243.48it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1179815.74it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1353358.81it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1340177.38it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1476233.82it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1414620.25it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1523059.67it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1388834.02it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1378038.89it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1360348.27it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1398101.33it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1438458.45it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1168599.34it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1308413.31it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1381342.55it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1446811.08it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1339398.55it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 1141399.06it/s]\n",
      "100%|██████████| 2198/2198 [00:00<00:00, 739360.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.71 s, sys: 1.52 s, total: 9.23 s\n",
      "Wall time: 6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rocks', 0.7492744326591492),\n",
       " ('personally', 0.746706485748291),\n",
       " ('falafels', 0.6939298510551453),\n",
       " ('baklava', 0.6934903860092163),\n",
       " ('comforting', 0.6809792518615723),\n",
       " ('drooling', 0.6801717877388),\n",
       " ('general', 0.6790015697479248),\n",
       " ('baba', 0.674885630607605),\n",
       " ('aye', 0.673746645450592),\n",
       " ('detailing', 0.6674149036407471)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dmm.wv.most_similar('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('those', 0.8215619921684265),\n",
       " ('movies', 0.8087788820266724),\n",
       " ('austen', 0.8035611510276794),\n",
       " ('scream', 0.8005440831184387),\n",
       " ('zombie', 0.7980297207832336),\n",
       " ('supernatural', 0.7947716116905212),\n",
       " ('extant', 0.7735164165496826),\n",
       " ('visual', 0.7508927583694458),\n",
       " ('skip', 0.7433120608329773),\n",
       " ('wonderfully', 0.7410240173339844)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dmm.wv.most_similar('hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = get_vectors(new_model, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7709090909090909"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
